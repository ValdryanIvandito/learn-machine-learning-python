{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0ee502-ef28-4c90-87d8-dd724c35c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "355d560d-59d9-4e41-bf27-63abc713c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4cacc2c-af8d-4256-a5a5-608856467b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi dataset menjadi data training dan data testing.\n",
    "# train_test_split akan memisahkan:\n",
    "#   - X_train : 80% data fitur untuk melatih model\n",
    "#   - X_test  : 20% data fitur untuk menguji model\n",
    "#   - y_train : 80% label target untuk training\n",
    "#   - y_test  : 20% label target untuk testing\n",
    "#\n",
    "# test_size=0.2  → 20% data dijadikan data uji\n",
    "# random_state=42 → agar pembagian data selalu sama setiap dijalankan\n",
    "\n",
    "      #             ┌──────────────────────────────────────┐\n",
    "      #             │        Dataset Lengkap (X, y)        │\n",
    "      #             │   Fitur: X                           │\n",
    "      #             │   Label: y                           │\n",
    "      #             └───────────────────┬──────────────────┘\n",
    "      #                                 │\n",
    "      #                                 │  train_test_split\n",
    "      #                                 │  (test_size = 0.2)\n",
    "      #                                 ▼\n",
    "      # ┌─────────────────────────────────────────────────────────────────┐\n",
    "      # │                                                                 │\n",
    "      # │                       Pembagian Dataset                         │\n",
    "      # │                                                                 │\n",
    "      # └───────────────┬───────────────────────────────┬─────────────────┘\n",
    "      #                 │                               │\n",
    "      #                 ▼                               ▼\n",
    "      #   ┌──────────────────────┐           ┌──────────────────────┐\n",
    "      #   │     Data Training    │           │      Data Testing    │\n",
    "      #   │       (80%)          │           │        (20%)         │\n",
    "      #   └──────────┬───────────┘           └──────────┬───────────┘\n",
    "      #              │                                    │\n",
    "      #              │                                    │\n",
    "      #      ┌───────▼────────┐                   ┌───────▼─────────┐\n",
    "      #      │ X_train (80%)  │                   │ X_test (20%)    │\n",
    "      #      │ fitur training │                   │ fitur testing   │\n",
    "      #      └────────────────┘                   └─────────────────┘\n",
    "      #               │                                     │\n",
    "      #               ▼                                     ▼\n",
    "      #      ┌────────────────┐                    ┌────────────────┐\n",
    "      #      │ y_train (80%)  │                    │ y_test (20%)   │\n",
    "      #      │ label training │                    │ label testing  │\n",
    "      #      └────────────────┘                    └────────────────┘\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5d97d20-9d96-4deb-bd45-281296779cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled_array = scaler.transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled_array, columns=iris_data.feature_names)\n",
    "X_test_scaled_array = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled_array, columns=iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7b9db6e-34af-42e7-991b-b04471da7157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SEBELUM SCALING ===\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         120.000000        120.000000         120.000000   \n",
      "mean            5.809167          3.061667           3.726667   \n",
      "std             0.823805          0.449123           1.752345   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.500000   \n",
      "50%             5.750000          3.000000           4.250000   \n",
      "75%             6.400000          3.400000           5.100000   \n",
      "max             7.700000          4.400000           6.700000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        120.000000  \n",
      "mean           1.183333  \n",
      "std            0.752289  \n",
      "min            0.100000  \n",
      "25%            0.300000  \n",
      "50%            1.300000  \n",
      "75%            1.800000  \n",
      "max            2.500000  \n",
      "=== SETELAH SCALING ===\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count       1.200000e+02      1.200000e+02       1.200000e+02   \n",
      "mean        1.754152e-15     -1.694940e-15      -2.294461e-16   \n",
      "std         1.004193e+00      1.004193e+00       1.004193e+00   \n",
      "min        -1.839628e+00     -2.373778e+00      -1.562535e+00   \n",
      "25%        -8.644522e-01     -5.850598e-01      -1.276006e+00   \n",
      "50%        -7.212234e-02     -1.378803e-01       2.998997e-01   \n",
      "75%         7.202076e-01      7.564785e-01       7.869979e-01   \n",
      "max         2.304867e+00      2.992376e+00       1.703889e+00   \n",
      "\n",
      "       petal width (cm)  \n",
      "count      1.200000e+02  \n",
      "mean      -2.960595e-17  \n",
      "std        1.004193e+00  \n",
      "min       -1.446088e+00  \n",
      "25%       -1.179118e+00  \n",
      "50%        1.557325e-01  \n",
      "75%        8.231577e-01  \n",
      "max        1.757553e+00  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== SEBELUM SCALING ===\")\n",
    "print(pd.DataFrame(X_train, columns=iris_data.feature_names).describe())\n",
    "\n",
    "print(\"=== SETELAH SCALING ===\")\n",
    "print(X_train_scaled.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a2a6d9a-3169-4ce9-9c71-e640075757f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contoh data sebelum scaling:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                4.6               3.6                1.0               0.2\n",
      "1                5.7               4.4                1.5               0.4\n",
      "2                6.7               3.1                4.4               1.4\n",
      "3                4.8               3.4                1.6               0.2\n",
      "4                4.4               3.2                1.3               0.2\n",
      "\n",
      "Contoh data setelah scaling:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -1.473937          1.203658          -1.562535         -1.312603\n",
      "1          -0.133071          2.992376          -1.276006         -1.045633\n",
      "2           1.085898          0.085709           0.385858          0.289218\n",
      "3          -1.230143          0.756479          -1.218701         -1.312603\n",
      "4          -1.717731          0.309299          -1.390618         -1.312603\n"
     ]
    }
   ],
   "source": [
    "print(\"Contoh data sebelum scaling:\")\n",
    "print(pd.DataFrame(X_train, columns=iris_data.feature_names).head())\n",
    "\n",
    "print(\"\\nContoh data setelah scaling:\")\n",
    "print(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffbcde5d-78f8-4961-86e5-3b599b83e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean yang dihitung scaler:\n",
      "[5.80916667 3.06166667 3.72666667 1.18333333]\n",
      "\n",
      "Standard deviation yang dihitung scaler:\n",
      "[0.82036535 0.44724776 1.74502786 0.74914766]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean yang dihitung scaler:\")\n",
    "print(scaler.mean_)\n",
    "\n",
    "print(\"\\nStandard deviation yang dihitung scaler:\")\n",
    "print(scaler.scale_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
